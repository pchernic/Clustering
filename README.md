# Clustering
Exploring Clustering methods in Machine Learning. 

1. **K-Means Clustering:**
   K-Means is a partitioning algorithm that divides a dataset into 'k' clusters, aiming to minimize the sum of squared distances between data points and their cluster centroids.

2. **Hierarchical Clustering:**
   Hierarchical clustering creates a tree-like structure of nested clusters, where each data point starts as its own cluster and is iteratively merged with its nearest neighbor based on a linkage criterion.

3. **DBSCAN (Density-Based Spatial Clustering of Applications with Noise):**
   DBSCAN groups data points into clusters based on their density, effectively identifying clusters of varying shapes and sizes while classifying outliers as noise.

4. **Agglomerative Clustering:**
   Agglomerative clustering starts with each data point as a separate cluster and then repeatedly merges the two closest clusters until only a single cluster remains, forming a hierarchical structure.

5. **Gaussian Mixture Model (GMM):**
   GMM assumes that data points are generated from a mixture of Gaussian distributions. It estimates these distributions to identify clusters and their associated probabilities for each data point.

6. **Mean-Shift Clustering:**
   Mean shift is a non-parametric clustering technique that identifies cluster centers by shifting a kernel density estimator towards regions of higher data point density.
